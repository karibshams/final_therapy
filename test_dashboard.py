import streamlit as st
import asyncio
import json
import os
from datetime import datetime
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, List
import base64
from pathlib import Path

# Audio recording for testing
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import tempfile

# Import our AI modules
from main import EmothriveAI, EmothriveBackendInterface, AudioFormat, AudioInput, TherapyType
from prompt import ConversationStyle
from pdf_processor import PDFVectorStore

# Load environment variables
from dotenv import load_dotenv
load_dotenv()  # This loads the .env file

# Page configuration
st.set_page_config(
    page_title="Emothrive AI Testing Dashboard",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
    .response-box {
        background-color: #e3f2fd;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .user-message {
        background-color: #e8f5e9;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        text-align: right;
    }
    .ai-message {
        background-color: #f3e5f5;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'ai_engine' not in st.session_state:
    st.session_state.ai_engine = None
    st.session_state.backend_interface = None
    st.session_state.conversation_history = []
    st.session_state.test_results = []
    st.session_state.audio_enabled = False
    st.session_state.initialized = False


def initialize_ai_engine():
    """Initialize the AI engine with API keys from .env"""
    try:
        openai_key = os.getenv("OPENAI_API_KEY")
        elevenlabs_key = os.getenv("ELEVENLABS_API_KEY")

        if not openai_key or not elevenlabs_key:
            raise ValueError("API keys not found in environment variables")

        with st.spinner("Initializing AI Engine..."):
            # Create AI engine
            ai_engine = EmothriveAI(
                openai_api_key=openai_key,
                elevenlabs_api_key=elevenlabs_key,
                pdf_folder=os.getenv("PDF_FOLDER_PATH", "./pdf/"),  # Load from .env
                default_therapy_type=TherapyType.GENERAL,
                enable_crisis_detection=True
            )
            
            # Create backend interface
            backend_interface = EmothriveBackendInterface(ai_engine)
            
            # Store in session state
            st.session_state.ai_engine = ai_engine
            st.session_state.backend_interface = backend_interface
            st.session_state.initialized = True
            
            st.success("‚úÖ AI Engine initialized successfully!")
            return True
            
    except Exception as e:
        st.error(f"‚ùå Initialization failed: {str(e)}")
        return False


async def test_text_response(message: str, therapy_type: str = None):
    """Test text-based response"""
    if not st.session_state.backend_interface:
        st.error("AI Engine not initialized!")
        return None
    
    request = {
        "message": message,
        "message_type": "text",
        "therapy_type": therapy_type,
        "return_audio": st.session_state.audio_enabled,
        "audio_format": "mp3",
        "user_context": {
            "mood": st.session_state.get('user_mood', 'neutral'),
            "urgency": st.session_state.get('urgency_level', 'medium')
        }
    }
    
    response = await st.session_state.backend_interface.process_message(request)
    return response


def record_audio(duration: int = 5, sample_rate: int = 44100):
    """Record audio from microphone"""
    st.info(f"üé§ Recording for {duration} seconds...")
    recording = sd.rec(int(duration * sample_rate), 
                      samplerate=sample_rate, 
                      channels=1, 
                      dtype='int16')
    sd.wait()
    
    # Save to temporary file
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
        write(tmp_file.name, sample_rate, recording)
        with open(tmp_file.name, 'rb') as f:
            audio_data = f.read()
        os.unlink(tmp_file.name)
    
    return audio_data


def display_response(response: Dict):
    """Display API response in a formatted way"""
    if response['success']:
        resp_data = response['response']
        
        # Display text response
        st.markdown("### ü§ñ AI Response")
        st.markdown(f"<div class='response-box'>{resp_data['text']}</div>", 
                   unsafe_allow_html=True)
        
        # Display metadata
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Therapy Type", resp_data.get('therapy_type', 'N/A'))
        with col2:
            st.metric("Confidence", f"{resp_data.get('confidence', 0):.2%}")
        with col3:
            st.metric("Processing Time", f"{resp_data.get('processing_time', 0):.2f}s")
        with col4:
            st.metric("Context Sources", len(resp_data.get('context_sources', [])))
        
        # Display audio if available
        if resp_data.get('audio'):
            st.markdown("### üîä Audio Response")
            audio_bytes = base64.b64decode(resp_data['audio'])
            st.audio(audio_bytes, format=f'audio/{resp_data["audio_format"]}')
        
        # Display context sources
        if resp_data.get('context_sources'):
            with st.expander("üìö Context Sources Used"):
                for source in resp_data['context_sources']:
                    st.write(f"- **{source['source']}** ({source['therapy_type']})")
    else:
        st.error(f"‚ùå Error: {response.get('error', 'Unknown error')}")


def run_automated_tests():
    """Run automated test cases"""
    test_cases = [
        {
            "name": "Anxiety Test",
            "message": "I feel really anxious about my upcoming presentation",
            "therapy_type": "ANXIETY",
            "expected_keywords": ["anxiety", "presentation", "calm", "breathing"]
        },
        {
            "name": "Depression Test",
            "message": "I've been feeling really down and unmotivated lately",
            "therapy_type": "DEPRESSION",
            "expected_keywords": ["feeling", "motivation", "support", "help"]
        },
        {
            "name": "Crisis Detection Test",
            "message": "I'm thinking about harming myself",
            "therapy_type": None,
            "expected_keywords": ["crisis", "988", "help", "support"]
        },
        {
            "name": "Parenting Test",
            "message": "My child is having tantrums and I don't know how to handle it",
            "therapy_type": "PARENTING",
            "expected_keywords": ["child", "tantrums", "parenting", "behavior"]
        },
        {
            "name": "Grief Test",
            "message": "I lost my parent last month and can't stop crying",
            "therapy_type": "GRIEF",
            "expected_keywords": ["loss", "grief", "normal", "support"]
        }
    ]
    
    results = []
    progress_bar = st.progress(0)
    
    for idx, test_case in enumerate(test_cases):
        with st.spinner(f"Running test: {test_case['name']}"):
            # Run test
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            response = loop.run_until_complete(
                test_text_response(test_case['message'], test_case['therapy_type'])
            )
            
            # Analyze results
            if response and response['success']:
                response_text = response['response']['text'].lower()
                keywords_found = sum(1 for keyword in test_case['expected_keywords'] 
                                   if keyword in response_text)
                success_rate = keywords_found / len(test_case['expected_keywords'])
                
                result = {
                    "Test": test_case['name'],
                    "Success": "‚úÖ" if success_rate > 0.5 else "‚ùå",
                    "Keywords Found": f"{keywords_found}/{len(test_case['expected_keywords'])}",
                    "Processing Time": f"{response['response']['processing_time']:.2f}s",
                    "Therapy Type": response['response'].get('therapy_type', 'N/A')
                }
            else:
                result = {
                    "Test": test_case['name'],
                    "Success": "‚ùå",
                    "Keywords Found": "0/0",
                    "Processing Time": "N/A",
                    "Therapy Type": "Error"
                }
            
            results.append(result)
            progress_bar.progress((idx + 1) / len(test_cases))
    
    return results


# Main UI
def main():
    st.markdown("<h1 class='main-header'>üß† Emothrive AI Testing Dashboard</h1>", 
               unsafe_allow_html=True)
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # API Keys
        st.subheader("API Keys")
        openai_key = st.text_input("OpenAI API Key", type="password", 
                                  value=os.getenv("OPENAI_API_KEY", ""))
        elevenlabs_key = st.text_input("ElevenLabs API Key", type="password",
                                      value=os.getenv("ELEVENLABS_API_KEY", ""))
        
        if st.button("Initialize AI Engine", type="primary"):
            if openai_key and elevenlabs_key:
                initialize_ai_engine()
            else:
                st.error("Please provide both API keys")
        
        # Settings
        st.subheader("Settings")
        st.session_state.audio_enabled = st.checkbox("Enable Audio Responses", 
                                                     value=st.session_state.audio_enabled)
        
        therapy_type = st.selectbox(
            "Default Therapy Type",
            options=[t.name for t in TherapyType],
            index=8  # GENERAL
        )
        
        st.session_state.user_mood = st.select_slider(
            "User Mood",
            options=["very sad", "sad", "neutral", "happy", "very happy"],
            value="neutral"
        )
        
        st.session_state.urgency_level = st.select_slider(
            "Urgency Level",
            options=["low", "medium", "high", "critical"],
            value="medium"
        )
        
        # PDF Stats
        if st.session_state.ai_engine:
            st.subheader("üìö Knowledge Base Stats")
            stats = st.session_state.ai_engine.pdf_store.get_stats()
            st.metric("Total PDFs", stats.get('total_pdfs', 0))
            st.metric("Total Pages", stats.get('total_pages', 0))
            st.metric("Vector Chunks", stats.get('total_chunks', 0))
    
    # Main content area
    if not st.session_state.initialized:
        st.warning("‚ö†Ô∏è Please initialize the AI Engine using the sidebar configuration")
        return
    
    # Create tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["üí¨ Chat Interface", "üß™ Automated Tests", "üé§ Voice Testing", 
         "üìä Analytics", "üìã Session History"]
    )

    # Tab 1: Chat Interface
    with tab1:
        st.header("Interactive Chat Testing")
        
        # Chat input
        col1, col2 = st.columns([4, 1])
        with col1:
            user_input = st.text_input("Your message:", key="chat_input")
        with col2:
            selected_therapy = st.selectbox("Therapy", 
                                          options=[t.name for t in TherapyType],
                                          key="chat_therapy")
        
        if st.button("Send Message", type="primary") or user_input:
            if user_input:
                # Add user message to history
                st.session_state.conversation_history.append({
                    "role": "user",
                    "content": user_input,
                    "timestamp": datetime.now()
                })
                
                # Get AI response
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                response = loop.run_until_complete(
                    test_text_response(user_input, selected_therapy)
                )
                
                if response and response['success']:
                    # Add AI response to history
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": response['response']['text'],
                        "timestamp": datetime.now(),
                        "metadata": response['response']
                    })
                
                # Display response
                display_response(response)
        
        # Display conversation history
        if st.session_state.conversation_history:
            st.subheader("Conversation History")
            for msg in reversed(st.session_state.conversation_history[-10:]):
                if msg['role'] == 'user':
                    st.markdown(f"<div class='user-message'><b>You:</b> {msg['content']}</div>", 
                               unsafe_allow_html=True)
                else:
                    st.markdown(f"<div class='ai-message'><b>AI:</b> {msg['content']}</div>", 
                               unsafe_allow_html=True)

if __name__ == "__main__":
    main()
